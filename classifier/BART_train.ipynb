{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rq37FtwvcX56",
    "outputId": "2ed523dd-f8f2-4706-cf44-98bbf6cc734f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 48.0M  100 48.0M    0     0  6335k      0  0:00:07  0:00:07 --:--:-- 10.7M\n"
     ]
    }
   ],
   "source": [
    "!curl -o hello.zip https://p5awqg.bn.files.1drv.com/y4mA-IEUekCe26UIJgz2ProYp4zvREkBRgWqgnpQ-CG1ogbzKqNUbf_okXphIRbqldqeOqjSn0jwkvV5LSbzBMylwoFNyA4tujk9iuT3QMASbP_BFRNbw4sE1AuDtduNKpuImWahZ9--9kftzW27Dryb3wqoc6ba4_KZwgBe75nCNekCKIYV4-vUXiUBEffjfIccX6vuipt7_iy2SStMBAIgw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOt4be4mvTMJ",
    "outputId": "4fb1e677-1a8b-4367-a3b8-a77a34330132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: tokenizers, safetensors, xxhash, dill, responses, multiprocess, huggingface-hub, transformers, datasets, evaluate\n",
      "Successfully installed datasets-2.14.5 dill-0.3.7 evaluate-0.4.0 huggingface-hub-0.17.2 multiprocess-0.70.15 responses-0.18.0 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2 xxhash-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDRVLmzIvIh-",
    "outputId": "f418414c-91e6-48fc-ff7e-5667c9135de0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 2.0.1+cu118\n",
      "Device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from statistics import median\n",
    "from pprint import pprint\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk import WordNetLemmatizer, PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW, Adam\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
    "import evaluate\n",
    "\n",
    "print(f'Pytorch version: {torch.__version__}')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    print(f'Device: {torch.cuda.get_device_name(torch.cuda.current_device())}')\n",
    "\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e5zZFHNviKZ",
    "outputId": "3398fe97-62e8-4a06-d8ab-9051e933870a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  hello.zip\n",
      " extracting: ILDC_single/ILDC_single.csv.zip  \n",
      " extracting: ILDC_single/README.md   \n"
     ]
    }
   ],
   "source": [
    "!unzip hello.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftKH4ysXvyNQ",
    "outputId": "d5b4ab2e-b8e9-41ea-c62c-d07e46925314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ILDC_single/ILDC_single.csv.zip\n",
      "  inflating: ILDC_single.csv         \n",
      "   creating: __MACOSX/\n",
      "  inflating: __MACOSX/._ILDC_single.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip ILDC_single/ILDC_single.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qaJB0RE2EwY4"
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, filePath: str, baseModelName: str):\n",
    "        self.filePath = filePath\n",
    "        # self.MAX_TOKENS = 16384\n",
    "        self.MAX_TOKENS = 1024\n",
    "        self.BATCH_SIZE = 1\n",
    "        self.baseModelName = baseModelName\n",
    "        self.EPOCHS = 2\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(baseModelName)\n",
    "\n",
    "# config = Config('./ILDC_single.csv',\n",
    "#                 'hyperonym/xlm-roberta-longformer-base-16384')\n",
    "config = Config('./ILDC_single.csv',\n",
    "                'allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CMDosbGim4-",
    "outputId": "d97fc463-e4d9-4725-edfa-71deb114628e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown token: <unk>, ID: 3\n",
      "Seperator token: </s>, ID: 2\n",
      "Padding token: <pad>, ID: 1\n",
      "mask token: <mask>, ID: 50264\n",
      "Sentence level classification token: <s>, ID: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Unknown token: {config.tokenizer.unk_token}, ID: {config.tokenizer.unk_token_id}')\n",
    "print(f'Seperator token: {config.tokenizer.sep_token}, ID: {config.tokenizer.sep_token_id}')\n",
    "print(f'Padding token: {config.tokenizer.pad_token}, ID: {config.tokenizer.pad_token_id}')\n",
    "print(f'mask token: {config.tokenizer.mask_token}, ID: {config.tokenizer.mask_token_id}')\n",
    "print(f'Sentence level classification token: {config.tokenizer.cls_token}, ID: {config.tokenizer.cls_token_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "m4i4f2-ovf05",
    "outputId": "86c63653-3e42-4835-afd8-8221e4aca5cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-52bc78d6-9115-406c-ba77-9af984149479\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F. NARIMAN, J. Leave granted. In 2008, the Pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2019_890.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S. THAKUR, J. Leave granted. These appeals ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2014_170.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Markandey Katju, J. Leave granted. Heard lear...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2010_721.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALTAMAS KABIR,J. Leave granted. The question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2008_1460.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CIVIL APPEAL NO. 598 OF 2007 K. MATHUR, J. Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2008_188.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52bc78d6-9115-406c-ba77-9af984149479')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-52bc78d6-9115-406c-ba77-9af984149479 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-52bc78d6-9115-406c-ba77-9af984149479');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ed3d8e96-b1c3-4d77-8f28-3d0fa89e4570\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed3d8e96-b1c3-4d77-8f28-3d0fa89e4570')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ed3d8e96-b1c3-4d77-8f28-3d0fa89e4570 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text  label  split  \\\n",
       "0   F. NARIMAN, J. Leave granted. In 2008, the Pu...      1  train   \n",
       "1   S. THAKUR, J. Leave granted. These appeals ar...      0  train   \n",
       "2   Markandey Katju, J. Leave granted. Heard lear...      1  train   \n",
       "3   ALTAMAS KABIR,J. Leave granted. The question ...      1  train   \n",
       "4   CIVIL APPEAL NO. 598 OF 2007 K. MATHUR, J. Th...      1  train   \n",
       "\n",
       "            name  \n",
       "0   2019_890.txt  \n",
       "1   2014_170.txt  \n",
       "2   2010_721.txt  \n",
       "3  2008_1460.txt  \n",
       "4   2008_188.txt  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(config.filePath)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lm0JV1ipvfyi",
    "outputId": "df6811d9-7244-42fb-c920-13950b809aee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.67, 0.2, 0.13]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data split percentages\n",
    "data_s = Counter(data['split'])\n",
    "num_rows = sum(data_s.values())\n",
    "[float(f'{val/num_rows:.2f}') for val in data_s.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfEOH2V2vfvq",
    "outputId": "3b75c3a1-d61a-4313-a310-a0b7718c6604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3147, 1: 1935})\n",
      "Counter({0: 497, 1: 497})\n",
      "Counter({1: 762, 0: 755})\n"
     ]
    }
   ],
   "source": [
    "train_ds = data[data['split'] == 'train'].drop(['split', 'name'], axis=1)\n",
    "dev_ds = data[data['split'] == 'dev'].drop(['split', 'name'], axis=1)\n",
    "test_ds = data[data['split'] == 'test'].drop(['split', 'name'], axis=1)\n",
    "\n",
    "del data\n",
    "\n",
    "print(Counter(train_ds['label']))\n",
    "print(Counter(dev_ds['label']))\n",
    "print(Counter(test_ds['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNNTmnjLH9uP"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class LegalDataset(Dataset):\n",
    "    def __init__(self, texts: list[str], labels: list[float]) -> None:\n",
    "        super(LegalDataset, self).__init__()\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.porter = PorterStemmer()\n",
    "\n",
    "    def __preprocess_text(self, data: str) -> str:\n",
    "        text: str = data.strip()\n",
    "        text = text.lower()\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        text = self.lemmatizer.lemmatize(text, 'v')\n",
    "        text = self.porter.stem(text)\n",
    "        return text\n",
    "\n",
    "    def __len__(self) -> int: return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, ix: int)-> dict[str, torch.Tensor]:\n",
    "        text = self.texts[ix]\n",
    "        # text = self.__preprocess_text(text)\n",
    "        label = torch.tensor(self.labels[ix], dtype=torch.float16)\n",
    "\n",
    "        inputs = config.tokenizer(\n",
    "            text=text,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=config.MAX_TOKENS,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        inputs = {k: v[0] for k, v in inputs.items()}\n",
    "        inputs['labels'] = label.type(torch.float32)\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXfUU9i8V99I"
   },
   "outputs": [],
   "source": [
    "hg_train_ds = LegalDataset(texts=train_ds['text'], labels=train_ds['label'])\n",
    "hg_dev_ds = LegalDataset(texts=dev_ds['text'], labels=dev_ds['label'])\n",
    "\n",
    "train_loader = DataLoader(hg_train_ds, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(hg_dev_ds, batch_size=config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDYe1iJEy5Sr"
   },
   "outputs": [],
   "source": [
    "del train_ds\n",
    "del dev_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HYhXf-oXUk2",
    "outputId": "85413ca1-1da6-4b4f-d679-c0ac13197a7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0,  347, 6372,  ...,  488,  223,    2]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([1.])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "{k:v for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTRuEQtXcl9d",
    "outputId": "f1365bd4-7123-41be-c74b-fcbed6b1fb6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing LongformerForSequenceClassification.\n",
      "\n",
      "All the weights of LongformerForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongformerForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification\\\n",
    "        .from_pretrained(config.baseModelName, from_tf=True, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B2UDDsqGwtaa",
    "outputId": "d86ad78b-ee74-4182-adee-1a7bde38987c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5377035264\n",
      "6348079104\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6wV-sLohCfO"
   },
   "outputs": [],
   "source": [
    "x = model.forward(**{k: v for k, v in batch.items()}, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yq5Xm_wy1WYU",
    "outputId": "f8a4af9a-a43b-447d-d242-199312b00c32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerSequenceClassifierOutput(loss=tensor(1.3237, grad_fn=<MseLossBackward0>), logits=tensor([[-0.1505]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None, global_attentions=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhLVobo1jgP9",
    "outputId": "e30046a7-596a-4005-ae17-86700253093f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('loss', tensor(1.3237, grad_fn=<MseLossBackward0>)),\n",
       " ('logits', tensor([[-0.1505]], grad_fn=<AddmmBackward0>)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = x.items()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxEaq2EkwsFb"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(params=model.parameters(), lr=3e-2)\n",
    "TRAIN_STEPS = len(train_loader) * config.BATCH_SIZE\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='linear',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=TRAIN_STEPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwD5fxeheDnW"
   },
   "outputs": [],
   "source": [
    "if device == 'cuda': torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ioh_Y692dc2V"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, epochs: int) -> None:\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.has_cuda else \"mps\" if torch.has_mps else \"cpu\"\n",
    "        )\n",
    "        self.epochs = epochs\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = Adam(model.parameters(), lr=3e-2)\n",
    "\n",
    "        num_train_steps = len(train_loader) * config.BATCH_SIZE\n",
    "\n",
    "        self.scheduler = get_scheduler(\n",
    "            name='linear',\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=num_train_steps\n",
    "        )\n",
    "\n",
    "        self.train_loader = None\n",
    "        self.valid_loader = None\n",
    "\n",
    "        self.best_model = {'loss': np.inf, 'weights': None}\n",
    "\n",
    "        self.history = {\n",
    "            'epoch': [],\n",
    "            'train_loss': [],\n",
    "            'valid_loss': []\n",
    "        }\n",
    "\n",
    "\n",
    "    def train_one_step(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.to(self.device)\n",
    "        (_, loss), yhat = self.model.forward(**batch).items()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def train_one_epoch(self, data_loader: DataLoader) -> torch.Tensor:\n",
    "        self.model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for batch in tqdm(self.train_loader):\n",
    "            loss = self.train_one_step(batch)\n",
    "            epoch_loss += loss.item()\n",
    "        print('training done')\n",
    "        return epoch_loss / len(self.train_loader)\n",
    "\n",
    "\n",
    "    def validate(self, data_loader: DataLoader) -> torch.Tensor:\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                for k, v in batch.items():\n",
    "                    batch[k] = v.to(self.device)\n",
    "\n",
    "                loss, yHat = self.model.forward(**batch).items()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        print('validation done')\n",
    "\n",
    "        return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "    def predict(self, input_ids: torch.Tensor,\n",
    "                token_type_ids: torch.Tensor,\n",
    "                attention_mask: torch.Tensor) -> np.ndarray:\n",
    "        yHat, _ = self.model.forward(input_ids=input_ids.to(self.device),\n",
    "                                     token_type_ids=token_type_ids.to(self.device),\n",
    "                                     attention_mask=attention_mask.to(self.device))\n",
    "        return yHat.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    def fit(self, train_loader: DataLoader, valid_loader: Optional[DataLoader] = None) -> None:\n",
    "\n",
    "        if self.train_loader is None and train_loader is None:\n",
    "            raise Exception(\"Train Loader cannot be None.\")\n",
    "\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            print(f'Training on Epoch #[{epoch + 1}/{self.epochs}]')\n",
    "\n",
    "            train_loss = self.train_one_epoch(self.train_loader)\n",
    "            if self.valid_loader:\n",
    "                valid_loss = self.validate(self.valid_loader)\n",
    "\n",
    "            self.history['epoch'].append(epoch)\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['valid_loss'].append(valid_loss)\n",
    "\n",
    "            if valid_loss < self.best_model['loss']:\n",
    "                self.best_model['loss'] = valid_loss\n",
    "                self.best_model['weights'] = self.model.state_dict()\n",
    "\n",
    "            torch.save(self.model, 'model_{epoch}.pth')\n",
    "\n",
    "            print(f\"Epoch[{epoch+1}/{self.epochs}]train_loss: {self.history['train_loss'][-1]}\\t valid_loss: {self.history['valid_loss'][-1]}\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqM87tJ9fwrA"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(epochs=config.EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563,
     "referenced_widgets": [
      "8d2c2c5136b8428cb12ef1e49cd490de",
      "4a811bd89a644ad0953a035dfd26c678",
      "cd6b9f1eb1e24b4483fe8d26594c0da1",
      "6684bf21fc3e462d81705d689489f85e",
      "6154362914bb4b6d989b6b349cb3b56c",
      "92208d22bdb74909b9b7f7bb846e9e0b",
      "f6ea4b491b334d89a4e70f0c3632b48c",
      "eb077550ffa24d33b54b7cdd6f120c4a",
      "2ef033dbd8704bf081e53cea8c2a9656",
      "447e15290f234b4bb38a69a0df21016d",
      "a4c7d5d5af1442d5abb09d3aef5570d9"
     ]
    },
    "id": "NEXzUhUJjCsl",
    "outputId": "5d631538-43a3-4190-fee8-78ef0d3920a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Epoch #[1/2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2c2c5136b8428cb12ef1e49cd490de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5082 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-c4610eccf83d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-c933dd873eaa>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training on Epoch #[{epoch + 1}/{self.epochs}]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-c933dd873eaa>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-c933dd873eaa>\u001b[0m in \u001b[0;36mtrain_one_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit(train_loader=train_loader, valid_loader=dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiGXJrTijH9e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(trainer.history['epoch'], trainer.history['train_loss'], label='Train')\n",
    "plt.plot(trainer.history['epoch'], trainer.history['valid_loss'], label='Valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mbest_model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Waha-_RjJar"
   },
   "outputs": [],
   "source": [
    "torch.save(trainer.best_model, 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bub-JZDKwsCn"
   },
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_dataloader,\n",
    "                epochs,\n",
    "                train_steps,\n",
    "                optimizer,\n",
    "                lr_scheduler):\n",
    "\n",
    "    progress_bar = tqdm(range(train_steps))\n",
    "    losses = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_dataloader:\n",
    "            # get batch data\n",
    "            print(batch.items())\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            print(batch)\n",
    "\n",
    "            # # get model output\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            # # get loss and backprop\n",
    "            # loss = outputs.loss\n",
    "            # losses.append(loss)\n",
    "\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            # lr_scheduler.step()\n",
    "\n",
    "            # # clear gradients\n",
    "            # optimizer.zero_grad()\n",
    "\n",
    "            # # update progress\n",
    "            # progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "te5Go3Zdy8P2"
   },
   "outputs": [],
   "source": [
    "# !export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vn_Tij1lyPc-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "train_model(model,\n",
    "            dev_dl,\n",
    "            EPOCHS,\n",
    "            TRAIN_STEPS,\n",
    "            optimizer,\n",
    "            lr_scheduler)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2ef033dbd8704bf081e53cea8c2a9656": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "447e15290f234b4bb38a69a0df21016d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a811bd89a644ad0953a035dfd26c678": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92208d22bdb74909b9b7f7bb846e9e0b",
      "placeholder": "​",
      "style": "IPY_MODEL_f6ea4b491b334d89a4e70f0c3632b48c",
      "value": "  1%"
     }
    },
    "6154362914bb4b6d989b6b349cb3b56c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6684bf21fc3e462d81705d689489f85e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_447e15290f234b4bb38a69a0df21016d",
      "placeholder": "​",
      "style": "IPY_MODEL_a4c7d5d5af1442d5abb09d3aef5570d9",
      "value": " 54/5082 [00:32&lt;47:04,  1.78it/s]"
     }
    },
    "8d2c2c5136b8428cb12ef1e49cd490de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4a811bd89a644ad0953a035dfd26c678",
       "IPY_MODEL_cd6b9f1eb1e24b4483fe8d26594c0da1",
       "IPY_MODEL_6684bf21fc3e462d81705d689489f85e"
      ],
      "layout": "IPY_MODEL_6154362914bb4b6d989b6b349cb3b56c"
     }
    },
    "92208d22bdb74909b9b7f7bb846e9e0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4c7d5d5af1442d5abb09d3aef5570d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd6b9f1eb1e24b4483fe8d26594c0da1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb077550ffa24d33b54b7cdd6f120c4a",
      "max": 5082,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ef033dbd8704bf081e53cea8c2a9656",
      "value": 54
     }
    },
    "eb077550ffa24d33b54b7cdd6f120c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6ea4b491b334d89a4e70f0c3632b48c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
